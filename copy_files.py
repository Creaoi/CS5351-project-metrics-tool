# -*- coding: utf-8 -*-
import os
import shutil
import re
import json
import pandas as pd
# è¿™ä¸ªä»£ç ä¸»è¦æ˜¯å¤åˆ¶æ–‡ä»¶çš„ï¼Œé€šè¿‡app.pyç”Ÿæˆçš„æ–‡ä»¶åŸæœ¬åœ¨dataæ–‡ä»¶ï¼Œ
# ä½†æ˜¯å‰ç«¯å¿…é¡»è¦åœ¨frontend/publicæ–‡ä»¶å¤¹ä¸‹è¯»å–è¿™äº›æ–‡ä»¶ï¼Œ
# æ‰€ä»¥éœ€è¦ä¸€ä¸ªè„šæœ¬æŠŠè¿™äº›æ–‡ä»¶å¤åˆ¶è¿‡å»ï¼Œå¦‚æœåªæœ‰mdæ–‡ä»¶ä¼šé¡ºä¾¿ç”Ÿæˆjsonæ–‡ä»¶

# ----------------------------------------------------
# Configuration Paths
# ----------------------------------------------------
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
DATA_SOURCE_DIR = os.path.join(PROJECT_ROOT, 'data')
FRONTEND_PUBLIC_DIR = os.path.join(PROJECT_ROOT, 'frontend', 'public')
FILES_TO_COPY = [
    'burnout.json',
    'issue_metrics.json',
    'issue_metrics.md',
    'calculate_contributor_activity.json',
    'calculate_pr_review_efficiency.json',
    'response_time.json'
]


# ----------------------------------------------------
# ğŸ§© Step 1: Markdown â†’ JSON
# ----------------------------------------------------
def convert_md_to_json(md_path, json_path):
    """å°† issue_metrics.md è½¬æ¢ä¸º issue_metrics.jsonï¼ˆç¨³å®šç‰ˆï¼‰"""
    import io

    if not os.path.exists(md_path):
        print(f"âš ï¸ æœªæ‰¾åˆ° Markdown æ–‡ä»¶: {md_path}")
        return

    with open(md_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æå–æ‰€æœ‰ Markdown è¡¨æ ¼ï¼ˆæ¯ä¸ªè¡¨æ ¼è‡³å°‘ä¸¤è¡Œï¼‰
    tables = re.findall(r"(\|.*?\|(?:\n\|.*?\|)+)", content, re.DOTALL)
    if len(tables) < 3:
        print(f"âš ï¸ æœªæ£€æµ‹åˆ°å®Œæ•´è¡¨æ ¼ï¼Œè¯·æ£€æŸ¥ {md_path}ã€‚æ£€æµ‹åˆ° {len(tables)} å¼ ã€‚")
        return

    # è¾…åŠ©å‡½æ•°ï¼šæ¸…ç† Markdown è¡¨æ ¼å¹¶è½¬ä¸º DataFrame
    def parse_md_table(md_text):
        lines = [line.strip() for line in md_text.strip().split("\n") if line.strip()]
        # å»é™¤åˆ†éš”çº¿è¡Œï¼ˆä¾‹å¦‚ |---|---:|ï¼‰
        lines = [line for line in lines if not re.match(r"^\|?\s*:?-+:?\s*(\|\s*:?-+:?\s*)+\|?$", line)]
        if not lines:
            return pd.DataFrame()

        # ç»Ÿä¸€è¡¥é½æ¯è¡Œåˆ†éš”ç¬¦æ•°é‡
        max_pipes = max(line.count("|") for line in lines)
        fixed_lines = []
        for line in lines:
            parts = [p.strip() for p in line.split("|") if p.strip() != ""]
            while len(parts) < max_pipes - 1:
                parts.append("")
            fixed_lines.append("| " + " | ".join(parts) + " |")

        fixed_md = "\n".join(fixed_lines)
        df = pd.read_csv(io.StringIO(fixed_md), sep="|", engine="python")
        df = df.dropna(axis=1, how="all")
        df.columns = [c.strip() for c in df.columns]
        df = df.loc[:, df.columns.notna()]
        df = df[[c for c in df.columns if c and c != "---"]]
        df = df.map(lambda x: x.strip() if isinstance(x, str) else x)
        return df

    # --- 1ï¸âƒ£ æ¦‚è§ˆè¡¨ ---
    df1 = parse_md_table(tables[0])
    print(f"ğŸ§¾ ç¬¬1å¼ è¡¨åˆ—å: {list(df1.columns)}")

    overview = {}
    for _, row in df1.iterrows():
        metric = row.get("Metric") or row.iloc[0]
        overview[metric] = {
            "Average": row.get("Average"),
            "Median": row.get("Median"),
            "90th percentile": row.get("90th percentile")
        }

    # --- 2ï¸âƒ£ æ•°é‡è¡¨ ---
    df2 = parse_md_table(tables[1])
    print(f"ğŸ§¾ ç¬¬2å¼ è¡¨åˆ—å: {list(df2.columns)}")

    counts = {}
    for _, row in df2.iterrows():
        metric = row.get("Metric") or (row.iloc[0] if len(row) else None)
        count = row.get("Count") or (row.iloc[-1] if len(row) else None)
        if metric:
            try:
                counts[metric] = int(str(count).strip())
            except:
                counts[metric] = str(count).strip()

    # --- 3ï¸âƒ£ Issues è¡¨ ---
    df3 = parse_md_table(tables[2])
    print(f"ğŸ§¾ ç¬¬3å¼ è¡¨åˆ—å: {list(df3.columns)}")

    issues = []
    for _, row in df3.iterrows():
        issues.append({
            "title": row.get("Title"),
            "url": row.get("URL"),
            "assignee": row.get("Assignee"),
            "author": row.get("Author"),
            "time_to_first_response": None if row.get("Time to first response") == "None" else row.get("Time to first response"),
            "time_to_close": None if row.get("Time to close") == "None" else row.get("Time to close"),
            "time_to_answer": None if row.get("Time to answer") == "None" else row.get("Time to answer"),
        })

    json_data = {
        "overview": overview,
        "counts": counts,
        "issues": issues
    }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æˆåŠŸç”Ÿæˆ JSON æ–‡ä»¶: {json_path}")

# ----------------------------------------------------
# ğŸ§© Step 2: å¤åˆ¶æ–‡ä»¶åˆ°å‰ç«¯
# ----------------------------------------------------
def copy_files_to_frontend():
    print("--- 1. å¤åˆ¶æ–‡ä»¶åˆ°å‰ç«¯ Public ç›®å½• ---")

    if not os.path.exists(FRONTEND_PUBLIC_DIR):
        print(f"âš ï¸ Public ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸­ï¼š{FRONTEND_PUBLIC_DIR}")
        os.makedirs(FRONTEND_PUBLIC_DIR, exist_ok=True)

    if not os.path.exists(DATA_SOURCE_DIR):
        print(f"âŒ é”™è¯¯ï¼šæ•°æ®æºç›®å½•ä¸å­˜åœ¨: {DATA_SOURCE_DIR}")
        return

    for filename in FILES_TO_COPY:
        source_path = os.path.join(DATA_SOURCE_DIR, filename)
        destination_path = os.path.join(FRONTEND_PUBLIC_DIR, filename)

        if os.path.exists(source_path):
            shutil.copy(source_path, destination_path)
            print(f"âœ… å·²å¤åˆ¶ {filename} åˆ°å‰ç«¯ public/")
        else:
            print(f"âš ï¸ è·³è¿‡ {filename}ï¼ˆæœªæ‰¾åˆ°æºæ–‡ä»¶ï¼‰")


# ----------------------------------------------------
# ğŸ ä¸»æ‰§è¡Œé€»è¾‘
# ----------------------------------------------------
if __name__ == "__main__":
    md_path = os.path.join(DATA_SOURCE_DIR, "issue_metrics.md")
    json_path = os.path.join(DATA_SOURCE_DIR, "issue_metrics.json")

    print("=== å¼€å§‹ç”Ÿæˆ issue_metrics.json ===")
    convert_md_to_json(md_path, json_path)

    print("\n=== å¼€å§‹å¤åˆ¶æ–‡ä»¶ ===")
    copy_files_to_frontend()

    print("\nâœ… å…¨éƒ¨æµç¨‹å®Œæˆï¼")
